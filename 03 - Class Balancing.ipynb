{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from itertools import cycle\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.metrics import specificity_score\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# from xgboost import XGBoostClassifier\n",
    "\n",
    "from transformers import AmountCentsOnly, Log1pAmount, TimeToHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
    "    print(f'Recall: {recall_score(y_true, y_pred)}')\n",
    "    print(f'Precision: {precision_score(y_true, y_pred)}')\n",
    "    print(f'Specificity: {specificity_score(y_true, y_pred)}')\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / 'data'\n",
    "pkl_dir = data_dir / 'pkl'\n",
    "\n",
    "credit = pd.read_pickle(pkl_dir / 'credit_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = TimeToHour()\n",
    "log1p = Log1pAmount()\n",
    "cents = AmountCentsOnly()\n",
    "\n",
    "# samplers\n",
    "smote = SMOTE(random_state=0)\n",
    "adasyn = ADASYN(random_state=0)\n",
    "ncr = NeighbourhoodCleaningRule(random_state=0)\n",
    "\n",
    "# classifiers\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "gaussnb = GaussianNB()\n",
    "randforest = RandomForestClassifier(random_state=0)\n",
    "\n",
    "X, y = credit.drop(columns=['Class']), credit['Class']\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "class_names = np.array(['Non-Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182276, 178751)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_fraud = y_tr == 1\n",
    "X_tr_nf = X_tr[~is_fraud]\n",
    "y_tr_nf = y_tr[~is_fraud]\n",
    "X_tr_fr = X_tr[is_fraud]\n",
    "y_tr_fr = y_tr[is_fraud]\n",
    "\n",
    "data_tr_nf = pd.concat([X_tr_nf, y_tr_nf], axis=1)\n",
    "data_tr_fr = pd.concat([X_tr_fr, y_tr_fr], axis=1)\n",
    "\n",
    "loc = LocalOutlierFactor(contamination='auto')\n",
    "pred = loc.fit_predict(data_tr_nf)\n",
    "is_inlier = pred == 1\n",
    "\n",
    "data_in = pd.concat([data_tr_nf[is_inlier], data_tr_fr])\n",
    "X_tr_in, y_tr_in = data_in.drop(columns=['Class']), data_in['Class']\n",
    "\n",
    "len(X_tr), len(X_tr_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately imblearn doesn't allow FeatureUnions or nested Pipelines\n",
    "# so here is a workaround for trying to reduce code repetition\n",
    "\n",
    "def construct_pipeline(transform_steps, resample_steps, classifier):\n",
    "    return Pipeline(list(chain(transform_steps, resample_steps, [('classifier', classifier)])))\n",
    "\n",
    "\n",
    "transform_steps = [\n",
    "    ('hour', hour),\n",
    "    ('log1p', log1p),\n",
    "    ('cents', cents),\n",
    "]\n",
    "\n",
    "nosample_pipe = partial(construct_pipeline, transform_steps, [])\n",
    "adasyn_pipe = partial(construct_pipeline, transform_steps, [('adasyn', adasyn)])\n",
    "smote_pipe = partial(construct_pipeline, transform_steps, [('smote', smote)])\n",
    "ncr_smote_pipe = partial(construct_pipeline, transform_steps, [('ncr', ncr), ('smote', smote)])\n",
    "\n",
    "nosample_pipes = []\n",
    "adasyn_pipes = []\n",
    "smote_pipes = []\n",
    "ncr_smote_pipes = []\n",
    "\n",
    "classifiers = [logreg, gauss_nb, randforest]\n",
    "for clf in classifiers:\n",
    "    nosample_pipes.append(nosample_pipe(clf))\n",
    "    adasyn_pipes.append(adasyn_pipe(clf))\n",
    "    smote_pipes.append(smote_pipe(clf))\n",
    "    ncr_smote_pipes.append(ncr_smote_pipe(clf))\n",
    "\n",
    "all_pipes = list(chain(nosample_pipes, adasyn_pipes, smote_pipes, ncr_smote_pipes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteding/miniconda3/envs/fraud/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "for pipe in all_pipes:\n",
    "    y_pred = pipe.fit(X_tr, y_tr).predict(X_val)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in_preds = []\n",
    "for pipe in all_pipes:\n",
    "    y_in_pred = pipe.fit(X_tr_in, y_tr_in).predict(X_val)\n",
    "    y_in_preds.append(y_in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "NONE\n",
      "log reg\n",
      "0\n",
      "[[45466    18]\n",
      " [   31    54]]\n",
      "Accuracy: 0.9989247075862977\n",
      "Recall: 0.6352941176470588\n",
      "Precision: 0.75\n",
      "Specificity: 0.9996042564418257\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "1\n",
      "[[45022   462]\n",
      " [   26    59]]\n",
      "Accuracy: 0.9892909653492505\n",
      "Recall: 0.6941176470588235\n",
      "Precision: 0.11324376199616124\n",
      "Specificity: 0.9898425820068596\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "2\n",
      "[[45482     2]\n",
      " [   23    62]]\n",
      "Accuracy: 0.9994513814215804\n",
      "Recall: 0.7294117647058823\n",
      "Precision: 0.96875\n",
      "Specificity: 0.9999560284935362\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "ADASYN\n",
      "log reg\n",
      "3\n",
      "[[44535   949]\n",
      " [   10    75]]\n",
      "Accuracy: 0.9789549913318265\n",
      "Recall: 0.8823529411764706\n",
      "Precision: 0.0732421875\n",
      "Specificity: 0.9791355201829215\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "4\n",
      "[[44976   508]\n",
      " [   19    66]]\n",
      "Accuracy: 0.988435120366916\n",
      "Recall: 0.7764705882352941\n",
      "Precision: 0.11498257839721254\n",
      "Specificity: 0.9888312373581919\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "5\n",
      "[[45480     4]\n",
      " [   17    68]]\n",
      "Accuracy: 0.9995391603941276\n",
      "Recall: 0.8\n",
      "Precision: 0.9444444444444444\n",
      "Specificity: 0.9999120569870724\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "SMOTE\n",
      "log reg\n",
      "6\n",
      "[[44678   806]\n",
      " [    9    76]]\n",
      "Accuracy: 0.982115034343523\n",
      "Recall: 0.8941176470588236\n",
      "Precision: 0.08616780045351474\n",
      "Specificity: 0.9822794828950839\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "7\n",
      "[[45010   474]\n",
      " [   21    64]]\n",
      "Accuracy: 0.9891373521472931\n",
      "Recall: 0.7529411764705882\n",
      "Precision: 0.11895910780669144\n",
      "Specificity: 0.9895787529680767\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "8\n",
      "[[45481     3]\n",
      " [   15    70]]\n",
      "Accuracy: 0.9996049946235379\n",
      "Recall: 0.8235294117647058\n",
      "Precision: 0.958904109589041\n",
      "Specificity: 0.9999340427403043\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "NCR SMOTE\n",
      "log reg\n",
      "9\n",
      "[[44687   797]\n",
      " [    9    76]]\n",
      "Accuracy: 0.982312537031754\n",
      "Recall: 0.8941176470588236\n",
      "Precision: 0.08705612829324169\n",
      "Specificity: 0.9824773546741712\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "10\n",
      "[[45011   473]\n",
      " [   21    64]]\n",
      "Accuracy: 0.9891592968904299\n",
      "Recall: 0.7529411764705882\n",
      "Precision: 0.1191806331471136\n",
      "Specificity: 0.9896007387213086\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "11\n",
      "[[45479     5]\n",
      " [   17    68]]\n",
      "Accuracy: 0.9995172156509908\n",
      "Recall: 0.8\n",
      "Precision: 0.9315068493150684\n",
      "Specificity: 0.9998900712338404\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "sampler_names = cycle(['none', 'adasyn', 'smote', 'ncr smote'])\n",
    "estimator_names = cycle(['log reg', 'gauss nb', 'rand forest'])\n",
    "\n",
    "for idx, (y_pred) in enumerate(y_in_preds):\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    if idx % len(classifiers) == 0:\n",
    "        print('=' * 100)\n",
    "        print(next(sampler_names).upper())\n",
    "    print(next(estimator_names))\n",
    "    print(idx)\n",
    "    print(cm)\n",
    "    print(f'Accuracy: {accuracy_score(y_val, y_pred)}')\n",
    "    print(f'Recall: {recall_score(y_val, y_pred)}')\n",
    "    print(f'Precision: {precision_score(y_val, y_pred)}')\n",
    "    print(f'Specificity: {specificity_score(y_val, y_pred)}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "NONE\n",
      "log reg\n",
      "0\n",
      "[[45476     8]\n",
      " [   38    47]]\n",
      "Accuracy: 0.998990541815708\n",
      "Recall: 0.5529411764705883\n",
      "Precision: 0.8545454545454545\n",
      "Specificity: 0.9998241139741447\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "1\n",
      "[[45157   327]\n",
      " [   28    57]]\n",
      "Accuracy: 0.9922096161864425\n",
      "Recall: 0.6705882352941176\n",
      "Precision: 0.1484375\n",
      "Specificity: 0.9928106586931669\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "2\n",
      "[[45481     3]\n",
      " [   26    59]]\n",
      "Accuracy: 0.9993636024490333\n",
      "Recall: 0.6941176470588235\n",
      "Precision: 0.9516129032258065\n",
      "Specificity: 0.9999340427403043\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "ADASYN\n",
      "log reg\n",
      "3\n",
      "[[44720   764]\n",
      " [   10    75]]\n",
      "Accuracy: 0.983014768812131\n",
      "Recall: 0.8823529411764706\n",
      "Precision: 0.08939213349225268\n",
      "Specificity: 0.983202884530824\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "4\n",
      "[[45103   381]\n",
      " [   21    64]]\n",
      "Accuracy: 0.9911782132590138\n",
      "Recall: 0.7529411764705882\n",
      "Precision: 0.14382022471910114\n",
      "Specificity: 0.9916234280186439\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "5\n",
      "[[45482     2]\n",
      " [   17    68]]\n",
      "Accuracy: 0.9995830498804011\n",
      "Recall: 0.8\n",
      "Precision: 0.9714285714285714\n",
      "Specificity: 0.9999560284935362\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "SMOTE\n",
      "log reg\n",
      "6\n",
      "[[44813   671]\n",
      " [   11    74]]\n",
      "Accuracy: 0.985033685180715\n",
      "Recall: 0.8705882352941177\n",
      "Precision: 0.09932885906040269\n",
      "Specificity: 0.9852475595813912\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "7\n",
      "[[45126   358]\n",
      " [   22    63]]\n",
      "Accuracy: 0.991660997608023\n",
      "Recall: 0.7411764705882353\n",
      "Precision: 0.1496437054631829\n",
      "Specificity: 0.9921291003429777\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "8\n",
      "[[45481     3]\n",
      " [   19    66]]\n",
      "Accuracy: 0.9995172156509908\n",
      "Recall: 0.7764705882352941\n",
      "Precision: 0.9565217391304348\n",
      "Specificity: 0.9999340427403043\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "NCR SMOTE\n",
      "log reg\n",
      "9\n",
      "[[44812   672]\n",
      " [   11    74]]\n",
      "Accuracy: 0.9850117404375782\n",
      "Recall: 0.8705882352941177\n",
      "Precision: 0.09919571045576407\n",
      "Specificity: 0.9852255738281593\n",
      "--------------------------------------------------\n",
      "gauss nb\n",
      "10\n",
      "[[45126   358]\n",
      " [   22    63]]\n",
      "Accuracy: 0.991660997608023\n",
      "Recall: 0.7411764705882353\n",
      "Precision: 0.1496437054631829\n",
      "Specificity: 0.9921291003429777\n",
      "--------------------------------------------------\n",
      "rand forest\n",
      "11\n",
      "[[45480     4]\n",
      " [   16    69]]\n",
      "Accuracy: 0.9995611051372644\n",
      "Recall: 0.8117647058823529\n",
      "Precision: 0.9452054794520548\n",
      "Specificity: 0.9999120569870724\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "sampler_names = cycle(['none', 'adasyn', 'smote', 'ncr smote'])\n",
    "estimator_names = cycle(['log reg', 'gauss nb', 'rand forest'])\n",
    "\n",
    "for idx, (y_pred) in enumerate(y_preds):\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    if idx % len(classifiers) == 0:\n",
    "        print('=' * 100)\n",
    "        print(next(sampler_names).upper())\n",
    "    print(next(estimator_names))\n",
    "    print(idx)\n",
    "    print(cm)\n",
    "    print(f'Accuracy: {accuracy_score(y_val, y_pred)}')\n",
    "    print(f'Recall: {recall_score(y_val, y_pred)}')\n",
    "    print(f'Precision: {precision_score(y_val, y_pred)}')\n",
    "    print(f'Specificity: {specificity_score(y_val, y_pred)}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
