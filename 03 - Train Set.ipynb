{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# samplers\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# transformers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AmountCentsOnly\n",
    "from transformers import Log1pAmount\n",
    "from transformers import TimeToHour\n",
    "\n",
    "# estimators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# misc\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / 'data'\n",
    "pkl_dir = data_dir / 'pkl'\n",
    "\n",
    "credit = pd.read_pickle(pkl_dir / 'credit_train.pkl')\n",
    "X, y = credit.drop(columns=['Class']), credit['Class']\n",
    "\n",
    "\n",
    "# remove outliers from non-fraud samples to see if it performs better\n",
    "is_fraud = (y == 1)\n",
    "fraud = credit[is_fraud]\n",
    "nonfraud = credit[~is_fraud]\n",
    "\n",
    "loc = LocalOutlierFactor(contamination='auto')\n",
    "loc_pred = loc.fit_predict(nonfraud)\n",
    "is_inlier = (loc_pred == 1)\n",
    "\n",
    "credit_in = pd.concat([nonfraud[is_inlier], fraud])\n",
    "X_in, y_in = credit_in.drop(columns=['Class']), credit_in['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_name(pipeline, sep=' -> ', method='keys'):\n",
    "    assert method in ['keys', 'values']\n",
    "    steps = getattr(pipeline.named_steps, method)()\n",
    "    if method == 'values':\n",
    "        steps = (type(obj).__name__ for obj in steps)\n",
    "    return sep.join(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers\n",
    "hour = TimeToHour()\n",
    "log1p = Log1pAmount()\n",
    "cents = AmountCentsOnly()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "transform_steps = [\n",
    "    ('hour', hour),\n",
    "    ('log1p', log1p),\n",
    "    ('cents', cents),\n",
    "    ('scaler', scaler),\n",
    "]\n",
    "\n",
    "\n",
    "# samplers\n",
    "adasyn = ADASYN(random_state=0)\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "\n",
    "# classifier\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# pipelines\n",
    "no_sampling_pipe = Pipeline(transform_steps + [('logreg', logreg)])\n",
    "smote_pipe = Pipeline(transform_steps + [('smote', smote), ('logreg', logreg)])\n",
    "adasyn_pipe = Pipeline(transform_steps + [('adasyn', adasyn), ('logreg', logreg)])\n",
    "\n",
    "all_pipes = [no_sampling_pipe, smote_pipe, adasyn_pipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hour -> log1p -> cents -> scaler -> logreg',\n",
       " 'hour -> log1p -> cents -> scaler -> smote -> logreg',\n",
       " 'hour -> log1p -> cents -> scaler -> adasyn -> logreg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pipeline_name(pipe) for pipe in all_pipes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_cv(X, y, pipelines):\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    for pipe in pipelines:\n",
    "        steps = pipeline_name(pipe)\n",
    "        scores = []\n",
    "        print('=' * 100)\n",
    "        print(steps, '\\n')\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "            y_pred = pipe.fit(X_train, y_train).predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            score = recall_score(y_test, y_pred)\n",
    "            print(f\"Recall: {score:.2%}\")\n",
    "            print(cm, '\\n')\n",
    "            scores.append(score)\n",
    "        print(f\"\\nMean Recall: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "hour -> log1p -> cents -> scaler -> logreg \n",
      "\n",
      "Recall: 55.70%\n",
      "[[45484     7]\n",
      " [   35    44]] \n",
      "\n",
      "Recall: 60.26%\n",
      "[[45484     7]\n",
      " [   31    47]] \n",
      "\n",
      "Recall: 66.67%\n",
      "[[45481    10]\n",
      " [   26    52]] \n",
      "\n",
      "Recall: 57.69%\n",
      "[[45486     5]\n",
      " [   33    45]] \n",
      "\n",
      "Recall: 56.41%\n",
      "[[45485     5]\n",
      " [   34    44]] \n",
      "\n",
      "\n",
      "Mean Recall: 0.5934436871145732\n",
      "====================================================================================================\n",
      "hour -> log1p -> cents -> scaler -> smote -> logreg \n",
      "\n",
      "Recall: 87.34%\n",
      "[[44416  1075]\n",
      " [   10    69]] \n",
      "\n",
      "Recall: 92.31%\n",
      "[[44312  1179]\n",
      " [    6    72]] \n",
      "\n",
      "Recall: 89.74%\n",
      "[[44289  1202]\n",
      " [    8    70]] \n",
      "\n",
      "Recall: 88.46%\n",
      "[[44308  1183]\n",
      " [    9    69]] \n",
      "\n",
      "Recall: 93.59%\n",
      "[[44272  1218]\n",
      " [    5    73]] \n",
      "\n",
      "\n",
      "Mean Recall: 0.9028886725089256\n",
      "====================================================================================================\n",
      "hour -> log1p -> cents -> scaler -> adasyn -> logreg \n",
      "\n",
      "Recall: 89.87%\n",
      "[[41708  3783]\n",
      " [    8    71]] \n",
      "\n",
      "Recall: 93.59%\n",
      "[[41167  4324]\n",
      " [    5    73]] \n",
      "\n",
      "Recall: 89.74%\n",
      "[[41546  3945]\n",
      " [    8    70]] \n",
      "\n",
      "Recall: 92.31%\n",
      "[[41141  4350]\n",
      " [    6    72]] \n",
      "\n",
      "Recall: 96.15%\n",
      "[[41304  4186]\n",
      " [    3    75]] \n",
      "\n",
      "\n",
      "Mean Recall: 0.9233365790327817\n"
     ]
    }
   ],
   "source": [
    "pipeline_cv(X, y, all_pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "hour -> log1p -> cents -> scaler -> logreg \n",
      "\n",
      "Recall: 64.56%\n",
      "[[44726     6]\n",
      " [   28    51]] \n",
      "\n",
      "Recall: 62.82%\n",
      "[[44727     4]\n",
      " [   29    49]] \n",
      "\n",
      "Recall: 74.36%\n",
      "[[44724     7]\n",
      " [   20    58]] \n",
      "\n",
      "Recall: 66.67%\n",
      "[[44728     3]\n",
      " [   26    52]] \n",
      "\n",
      "Recall: 62.82%\n",
      "[[44727     4]\n",
      " [   29    49]] \n",
      "\n",
      "\n",
      "Mean Recall: 0.6624472573839661\n",
      "====================================================================================================\n",
      "hour -> log1p -> cents -> scaler -> smote -> logreg \n",
      "\n",
      "Recall: 87.34%\n",
      "[[43647  1085]\n",
      " [   10    69]] \n",
      "\n",
      "Recall: 92.31%\n",
      "[[43572  1159]\n",
      " [    6    72]] \n",
      "\n",
      "Recall: 89.74%\n",
      "[[43540  1191]\n",
      " [    8    70]] \n",
      "\n",
      "Recall: 88.46%\n",
      "[[43550  1181]\n",
      " [    9    69]] \n",
      "\n",
      "Recall: 93.59%\n",
      "[[43524  1207]\n",
      " [    5    73]] \n",
      "\n",
      "\n",
      "Mean Recall: 0.9028886725089256\n",
      "====================================================================================================\n",
      "hour -> log1p -> cents -> scaler -> adasyn -> logreg \n",
      "\n",
      "Recall: 89.87%\n",
      "[[40957  3775]\n",
      " [    8    71]] \n",
      "\n",
      "Recall: 94.87%\n",
      "[[40558  4173]\n",
      " [    4    74]] \n",
      "\n",
      "Recall: 84.62%\n",
      "[[40856  3875]\n",
      " [   12    66]] \n",
      "\n",
      "Recall: 89.74%\n",
      "[[40588  4143]\n",
      " [    8    70]] \n",
      "\n",
      "Recall: 94.87%\n",
      "[[40669  4062]\n",
      " [    4    74]] \n",
      "\n",
      "\n",
      "Mean Recall: 0.9079519636481661\n"
     ]
    }
   ],
   "source": [
    "pipeline_cv(X_in, y_in, all_pipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, removing non-fraud outliers does not help the performance, so I will be using the entire test set for the final evaluation. \n",
    "\n",
    "While ADASYN performed ~2% better than SMOTE in terms of recall, my metric of choice, SMOTE had 4x fewer false positives. Thus depending on the cost of letting a true-fraudster be uncaught vs auditing people classified as fraudsters, we would choose one variant over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_params = dict(\n",
    "    smote__k_neighbors=range(4, 6),\n",
    "    smote__random_state=[0],\n",
    "    logreg__C=np.power(10.0, range(-2, 3)),\n",
    "    logreg__penalty=['l1', 'l2'],\n",
    "    logreg__solver=['liblinear'],\n",
    "    logreg__random_state=[0],\n",
    ")\n",
    "smote_gridcv = GridSearchCV(smote_pipe, smote_params, scoring='recall', iid=False, cv=5, verbose=2, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_gridcv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054527750730281"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_gridcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 0.01,\n",
       " 'logreg__penalty': 'l1',\n",
       " 'logreg__random_state': 0,\n",
       " 'logreg__solver': 'liblinear',\n",
       " 'smote__k_neighbors': 4,\n",
       " 'smote__random_state': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_gridcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_best = smote_gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_dir / 'smote_best.pkl', 'wb') as fp:\n",
    "    pickle.dump(smote_best, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADASYN - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_params = dict(\n",
    "    adasyn__n_neighbors=range(4, 6),\n",
    "    adasyn__random_state=[0],\n",
    "    logreg__C=np.power(10.0, range(-2, 3)),\n",
    "    logreg__penalty=['l1', 'l2'],\n",
    "    logreg__solver=['liblinear'],\n",
    "    logreg__random_state=[0],\n",
    ")\n",
    "adasyn_gridcv = GridSearchCV(adasyn_pipe, adasyn_params, scoring='recall', iid=False, cv=5, verbose=2, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_gridcv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9233365790327817"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn_gridcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adasyn__n_neighbors': 5,\n",
       " 'adasyn__random_state': 0,\n",
       " 'logreg__C': 1.0,\n",
       " 'logreg__penalty': 'l1',\n",
       " 'logreg__random_state': 0,\n",
       " 'logreg__solver': 'liblinear'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn_gridcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_best = adasyn_gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_dir / 'adasyn_best.pkl', 'wb') as fp:\n",
    "    pickle.dump(adasyn_best, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
